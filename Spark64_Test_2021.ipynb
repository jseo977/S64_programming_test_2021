{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Spark64_Test_2021.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q5q-GvDOXpdR"
      },
      "source": [
        "# Spark 64 Test\n",
        "This is my submission for the Spark 64 Natural Language Processing technical test.\n",
        "\n",
        "I used a pre-trained model that is based off of the BERT model, from the Huggingface (ðŸ¤—) model repository. To run the notebook, ***simply drag-and-drop the .csv folder that you wish to analyse and press Runtime > Run all***. Appendeded at the bottom of the notebook is a summary of my work and my key findings from the sample dataset. I recommend reading through the 'Findings and Final Thoughts' chapter whilst the notebook is running.\n",
        "\n",
        "Please input the name of the .csv file (with the extension) in the below cell before running (has been set to \"support_tweets.csv\" by default). If no name is given, the first .csv files in the root directory will be analysed."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "scOxPqigWVjG"
      },
      "source": [
        "# Read in files.\n",
        "file_dir = 'support_tweets.csv' #@param {type:\"string\"}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "viBwPunO3Lpb"
      },
      "source": [
        "# Imports, File I/O and Configurations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tCcjUW5E4Oj0"
      },
      "source": [
        "## Install Modules\n",
        "Install transformers to initialise the pre-trainied NLP model pipeline."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EG4kAdh7XmJm"
      },
      "source": [
        "# Install necessary modules (Not pre-loaded on Colab)\n",
        "%%capture\n",
        "!pip install transformers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "62MhoZN14Trf"
      },
      "source": [
        "## Imports\n",
        "Import necessary modules to run the code."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P3CQ6lQSDGaf"
      },
      "source": [
        "# Import necessary modules\n",
        "from transformers import BertTokenizer, TFBertForSequenceClassification\n",
        "from transformers import InputExample, InputFeatures\n",
        "from transformers import AutoModel, AutoTokenizer, pipeline\n",
        "from collections import Counter\n",
        "\n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import multiprocessing\n",
        "import plotly.express as px\n",
        "\n",
        "from time import time, sleep\n",
        "from glob import glob\n",
        "from threading import Thread\n",
        "from itertools import repeat"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4G-MiXdv4bmg"
      },
      "source": [
        "## File I/O\n",
        "Read in the appropriate files.\n",
        "\n",
        "Please provide the filename/directory to the file in the form on the right and click run."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KI8xzf8rYHF2"
      },
      "source": [
        "if file_dir == '':\n",
        "    file_dir = glob('*.csv')\n",
        "    tweets = pd.read_csv(file_dir[0])\n",
        "else:\n",
        "    tweets = pd.read_csv(file_dir)\n",
        "tweets.isnull().values.any()\n",
        "tweets = tweets.values.tolist()\n",
        "len(tweets)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VOekuXzbeslu"
      },
      "source": [
        "## Preprocessings\n",
        "Preprocess input tweets dataset to remove excess punctuation, lower case all letters."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ROuX-qFzGNu8"
      },
      "source": [
        "# Convert input .csv file data into a usable format\n",
        "tweets_temp = np.array(tweets)\n",
        "tweets_temp.flatten()\n",
        "# Lower case all characters\n",
        "master_string = \" \".join([str(tweet[0]).lower() for tweet in tweets_temp.tolist()])\n",
        "# Remove punctuation except for '@' characters\n",
        "master_string = master_string.translate(str.maketrans('', '', '!\"#$%&/()*+,-./:;<=>?[\\\\]^_`{|}~')).split()\n",
        "unique_words = list(set(master_string))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dKyMcYBF2m0_"
      },
      "source": [
        "##Retrieve the most common word(s)\n",
        "As we do not need to do sentiment analysis to compute the number of each word in the .csv file, we can find the most common words immediately after string pre-processing.\n",
        "\n",
        "Input the amount of top words you wish to retrieve from the dataset in the form on the right."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IZOBfQ6e4FUt"
      },
      "source": [
        "# Define how many of the most common words you\n",
        "# wish to see\n",
        "number_occurances = 3 #@param {type:\"number\"}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3XBFdHMf2rCJ"
      },
      "source": [
        "# Pass the master_string list to an instance of the Counter class.\n",
        "counter = Counter(master_string)\n",
        "  \n",
        "# Output the most common words\n",
        "most_occur = counter.most_common(int(number_occurances))\n",
        "\n",
        "# Print the 'number_occurances' amount of most frequent words.\n",
        "print('The %i most frequent word(s) were(is):'%(number_occurances))\n",
        "for pair in most_occur:\n",
        "    print('\\'%s\\', appearing %i times'% (pair[0], pair[1]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UgrAp5NaXYB8"
      },
      "source": [
        "# BERT Model\n",
        "Create a pipeline from a pre-trained BERT NLP sentiment analysis model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ORnpYhSk4wBY"
      },
      "source": [
        "## Initialise BERT Model\n",
        "Run the cell below to create the sentiment analysis polarity model pipeline."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qXWI9YFxZC6R"
      },
      "source": [
        "# Create Pipeline for sentiment analysis using the pre-trained BERTweet model\n",
        "sentiment_analysis = pipeline('sentiment-analysis', model='distilbert-base-uncased-finetuned-sst-2-english')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BZQL0efJ47v1"
      },
      "source": [
        "# Average sentiment of tweets\n",
        "Average sentiment of tweets containing a certain word/handle/string.\n",
        "This is currently written specifically for the outputs of the `distilbert-base-uncased-finetuned-sst-2-english` pre-trained model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VkXKSmlitUdq"
      },
      "source": [
        "def average_sentiment_word(word:str, tweets_all:list) -> 'sentiment':\n",
        "    \"\"\" \n",
        "        Given a word and a list of strings, output the average sentiment of tweets\n",
        "        containing the word. The model will use the 'sentiment_analysis' pre-trained\n",
        "        model pipeline.\n",
        "        Author: Jae Min Seo\n",
        "        Inputs:\n",
        "        word: str\n",
        "            A Python string for which we will find the average sentiment of in the\n",
        "            given strings in the tweets_all list of strings.\n",
        "        tweets_all: list\n",
        "            A list containing all of the tweets/strings that we will analyse to\n",
        "            gauge/calculate the average sentiment. \n",
        "        Outputs:\n",
        "        word: str\n",
        "            The same string as the 'word' input. Repeated for ease of implementation\n",
        "            with the multiprocessing processes used to speed up code.\n",
        "        sentiment: float\n",
        "            A float containing the average sentiment of the tweets containing the\n",
        "            'word' string. Values in (0,1] have net average positive polarities \n",
        "            whilst values in [-1,0) have a net average negative polarity.\n",
        "            Returns 'None' if the word is not contained in any of the strings in\n",
        "            'tweets_all'.\n",
        "    \"\"\"\n",
        "    # Ensure that word is lower cased\n",
        "    word = word.lower()\n",
        "    sentiment = []\n",
        "    for tweet in tweets_all:\n",
        "        tweet = str(tweet).lower()\n",
        "        if word in tweet:\n",
        "            result = sentiment_analysis(tweet)\n",
        "            label = result[0]['label']\n",
        "            score = result[0]['score']\n",
        "            # Append results to sentiment list\n",
        "            if label == 'POSITIVE':\n",
        "                sentiment.append(score)\n",
        "            else:\n",
        "                sentiment.append(-1*score)\n",
        "    # Account for the case where the word does not exist in the tweets_all list\n",
        "    try:\n",
        "        return word, sum(sentiment)/len(sentiment)\n",
        "    except:\n",
        "        return word, None"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QOTIdjAIP7Jg"
      },
      "source": [
        "## Filter out words that appear less than a specific number of times\n",
        "Define the number of minimum occurances you wish to see of a word in in the .csv file before it is analysed by the NLP pipeline."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xl7YQhsAQPs0"
      },
      "source": [
        "minimum_occurances = 3 #@param {type:\"number\"}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TVghvSlZzm9s"
      },
      "source": [
        "# Filter out all words that appear less than 'minimum_occurances' number of times\n",
        "filtered_unique_words = [unique_word for unique_word in unique_words\n",
        "                         if master_string.count(unique_word) >= minimum_occurances]\n",
        "print('There are %i unique words that occur more than %i times.'%(len(filtered_unique_words), minimum_occurances))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gdnL5cT_7ZjB"
      },
      "source": [
        "## The average polarity of tweets containing certain words.\n",
        "This cell will attempt to compute the average sentiments of tweets containing a word that is passed into the `average_sentiment_word()` function.\n",
        "\n",
        "Note that this process may take a while (around 3 minutes with the sample dataset), and the operation will grow in time complexity with $O(n^2)$ operations (with inputs being the words being processed).\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8eNqp-bDZ0jC"
      },
      "source": [
        "# Iterate through each word to find the average sentiment of tweets containing each word\n",
        "# that appears more than 'minimum_occurance' of timees in the dataset of tweets\n",
        "max = len(filtered_unique_words)\n",
        "pool = multiprocessing.Pool(processes = 8)\n",
        "results = pool.starmap(average_sentiment_word, zip(filtered_unique_words, repeat(tweets)))\n",
        "results = np.array(results).reshape(max,2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DPyOETSpyTUp"
      },
      "source": [
        "## Getting the top few most polarised/divisive words\n",
        "Define how many of each category (positive, negative, neutral) words you wish to see from our exploration of the tweets dataset.\n",
        "\n",
        "Note that handles have been separated from normal words (handles can be processed in following cells)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "96ANB_eJySgY"
      },
      "source": [
        "top_occurances = 3 #@param {type:\"number\"}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dnEQGYK18-hB"
      },
      "source": [
        "Run the cell below to see the top polarity results for words only."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "66z4tYUlygIL"
      },
      "source": [
        "# Remove all None occurances and handles\n",
        "results_filtered = np.array([result for result in results if (result[1] and '@' not in result[0])])\n",
        "# Ensure results and polarities have the same shape\n",
        "polarities = [float(result) for result in results_filtered[:,1]]\n",
        "results_filtered = results_filtered.tolist()\n",
        "\n",
        "print('The most positive words appearing more than %i times were:'%(minimum_occurances))\n",
        "for i in range(top_occurances):\n",
        "    max = results_filtered.pop(np.argmax(polarities))\n",
        "    polarities.pop(np.argmax(polarities))\n",
        "    print(\"\\'%s\\' with a score of: %.4f\"%(max[0], float(max[1])))\n",
        "\n",
        "print('\\nThe most negative words appearing more than %i times were:'%(minimum_occurances))\n",
        "for i in range(top_occurances):\n",
        "    min = results_filtered.pop(np.argmin(polarities))\n",
        "    polarities.pop(np.argmin(polarities))\n",
        "    print(\"\\'%s\\' with a score of: %.4f\"%(min[0], float(min[1])))\n",
        "\n",
        "abs_polarities = [abs(val) for val in polarities]\n",
        "print('\\nThe most divisive words appearing more than %i times were:'%(minimum_occurances))\n",
        "for i in range(top_occurances):\n",
        "    div = results_filtered.pop(np.argmin(abs_polarities))\n",
        "    abs_polarities.pop(np.argmin(abs_polarities))\n",
        "    print(\"\\'%s\\' with a score of: %.4f\"%(div[0], float(div[1])))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nBXQc8HHgYMF"
      },
      "source": [
        "Run the cell below to see the top polarity results for handles only."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-TxgOItrAAna"
      },
      "source": [
        "# Remove all None scores\n",
        "results = np.array([result for result in results if result[1]])\n",
        "# Get an array of only handles (words including '@')\n",
        "handles = [word for word in results if '@' in word[0]]\n",
        "handles_polarity = [float(handle[1]) for handle in handles]\n",
        "\n",
        "print('The most positive tweets included the handles:')\n",
        "for i in range(top_occurances):\n",
        "    # Retrieve the most positive handles\n",
        "    index = np.argmax(np.array(handles_polarity))\n",
        "    max = handles.pop(index)\n",
        "    handles_polarity.pop(index)\n",
        "    print(\"\\'%s\\' with a score of: %.4f\"%(max[0], float(max[1])))\n",
        "\n",
        "print('\\nThe most negative tweets included the handles:')\n",
        "for i in range(top_occurances):\n",
        "    # Retrieve the most positive handles\n",
        "    index = np.argmin(np.array(handles_polarity))\n",
        "    min = handles.pop(index)\n",
        "    handles_polarity.pop(index)\n",
        "    print(\"\\'%s\\' with a score of: %.4f\"%(min[0], float(min[1])))\n",
        "\n",
        "abs_handles_polarity = [abs(val) for val in handles_polarity]\n",
        "print('\\nThe most divisive tweets included the handles:')\n",
        "for i in range(top_occurances):\n",
        "    # Retrieve the most positive handles\n",
        "    index = np.argmin(np.array(abs_handles_polarity))\n",
        "    div = handles.pop(index)\n",
        "    abs_handles_polarity.pop(index)\n",
        "    print(\"\\'%s\\' with a score of: %.4f\"%(div[0], float(div[1])))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wwuf-yhaAswh"
      },
      "source": [
        "# Visualising the data with Plotly Dash"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sPkWrIwSBh2Y"
      },
      "source": [
        "## Sort words\n",
        "Ascend-sorting words make them more easy to view and see patterns."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7LA5C3eOvhx8"
      },
      "source": [
        "# Sort all words, handles according to their average sentiment (ascending)\n",
        "results_sorted = sorted(results,key=lambda results: results[1])\n",
        "handles = [word for word in results if '@' in word[0]]\n",
        "handles_sorted = sorted(handles,key=lambda handles: handles[1])\n",
        "words = [result for result in results if (result[1] and '@' not in result[0])]\n",
        "words_sorted = sorted(words,key=lambda words: words[1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tO8ukOwyAkWz"
      },
      "source": [
        "## Sorted raw output for the sentiment polarity of the most frequent words & handles"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UQ5SxsqGwyRU"
      },
      "source": [
        "data = pd.DataFrame(results_sorted)\n",
        "data.columns = ['Words/Handles','Sentiment']\n",
        "fig = px.bar(data, x='Words/Handles', y='Sentiment',\n",
        "             hover_data=['Words/Handles','Sentiment'],color='Sentiment',\n",
        "             color_continuous_scale='Agsunset')\n",
        "\n",
        "fig.update_layout(\n",
        "    title=\"Sentiment Score of the most frequent words & handles\",\n",
        "    title_x=0.5,\n",
        "    xaxis_title=\"Words/Handles\",\n",
        "    yaxis_title=\"Sentiment Score\")\n",
        "\n",
        "fig.show(renderer=\"colab\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YEVzeATTCcKZ"
      },
      "source": [
        "## Sorted raw output for the sentiment polarity of the most frequent handles"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eXcR-hv7zDhD"
      },
      "source": [
        "data = pd.DataFrame(handles_sorted)\n",
        "data.columns = ['Handles','Sentiment']\n",
        "fig = px.bar(data, x='Handles', y='Sentiment',\n",
        "             hover_data=['Handles','Sentiment'],color='Sentiment',\n",
        "             color_continuous_scale='Agsunset')\n",
        "\n",
        "fig.update_layout(\n",
        "    title=\"Sentiment Score of the most frequent handles\",\n",
        "    title_x=0.5,\n",
        "    xaxis_title=\"Handles\",\n",
        "    yaxis_title=\"Sentiment Score\")\n",
        "\n",
        "fig.show(renderer=\"colab\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QG3GaGRdCe6v"
      },
      "source": [
        "## Sorted raw output for the sentiment polarity of the most frequent words"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gkp3zVVo_7f3"
      },
      "source": [
        "data = pd.DataFrame(words_sorted)\n",
        "data.columns = ['Words','Sentiment']\n",
        "fig = px.bar(data, x='Words', y='Sentiment',\n",
        "             hover_data=['Words','Sentiment'],color='Sentiment',\n",
        "             color_continuous_scale='Agsunset')\n",
        "\n",
        "fig.update_layout(\n",
        "    title=\"Sentiment Score of the most frequent words\",\n",
        "    title_x=0.5,\n",
        "    xaxis_title=\"Words\",\n",
        "    yaxis_title=\"Sentiment Score\")\n",
        "\n",
        "fig.show(renderer=\"colab\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4LJrRalS205X"
      },
      "source": [
        "# Findings and Final Thoughts"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bsvVuWSY27vM"
      },
      "source": [
        "From the pre-trained BERT model, we can observe some key statistics, here is a summary of the outputs:\n",
        "\n",
        "```\n",
        "There are 249 unique words that occur more than 3 times.\n",
        "```\n",
        "Not that interesting, moving on.\n",
        "```\n",
        "The 3 most frequent word(s) were(is):\n",
        "'the', appearing 105 times\n",
        "'to', appearing 87 times\n",
        "'you', appearing 65 times\n",
        "```\n",
        "Again, not that insightful. However, it is interesting to see that 'you' is one of the more frequently used words. From a brief glance at the dataset it is fair to say that it has come up a lot in accusational contexts.\n",
        "```\n",
        "The most positive words appearing more than 3 times were:\n",
        "'great' with a score of: 0.9928\n",
        "'together' with a score of: 0.9261\n",
        "'you're' with a score of: 0.6729\n",
        "\n",
        "The most negative words appearing more than 3 times were:\n",
        "'itâ€™s' with a score of: -0.9996\n",
        "'fix' with a score of: -0.9996\n",
        "'getting' with a score of: -0.9995\n",
        "\n",
        "The most divisive words appearing more than 3 times were:\n",
        "'address' with a score of: -0.0001\n",
        "'we' with a score of: -0.0002\n",
        "'out' with a score of: -0.0007\n",
        "```\n",
        "Not surprisingly, the word 'great' had a high sentimentality score. As we are dealing with tech support/complaint tweets it is fair to see that 'fix' has a very low address, as consumers may be using not-so-polite language to try and resolve their issue. Unlike the example output, the word 'we' appeared to be more divisive on average than net positive.\n",
        "\n",
        "```\n",
        "The most positive tweets included the handles:\n",
        "'@105840' with a score of: 0.5832\n",
        "'@105856' with a score of: 0.3143\n",
        "'@115861' with a score of: 0.2974\n",
        "\n",
        "The most negative tweets included the handles:\n",
        "'@tesco' with a score of: -0.9983\n",
        "'@virgintrains' with a score of: -0.9978\n",
        "'@115858' with a score of: -0.9975\n",
        "\n",
        "The most divisive tweets included the handles:\n",
        "'@115855' with a score of: 0.0012\n",
        "'@spotifycares' with a score of: 0.1133\n",
        "'@115865' with a score of: -0.1793\n",
        "```\n",
        "The most positive handles were all customers, and weren't the most polarised. The top two most negative tweets were companies that were receiving criticism, which is fair enough considering the nature of the tweets from which the dataset was sampled from, though it was interesting to see that Spotify had a very neutral average sentiment.\n",
        "\n",
        "The plotly outputs show that there is an overwhelming majority of words that had a net average negative sentiment from the dataset. It was interesting to note that even words like 'love' were negative, and this is because the other words around them had a anchoring effect on it, or other cases where there was clear sarcasm involved(eg. \"My apps stop working without warning and my phone freezes every five minutes! Love the new update @76099!!!!\"), which the BERT model does not appear the most competent at recognising. \n",
        "\n",
        "The plotly outputs are pasted below:\n",
        "###  Plotly outputs for both words and handles\n",
        "![Words/Handles](https://drive.google.com/uc?export=view&id=1BR5w-cxNQ33zuSGfOS_8P9ma1ME8bnXZ)\n",
        "(https://drive.google.com/uc?export=view&id=1BR5w-cxNQ33zuSGfOS_8P9ma1ME8bnXZ)\n",
        "### Plotly outputs for handles only\n",
        "![Handles](https://drive.google.com/uc?export=view&id=1q0eWUEj8YWJlYF-lqzD5bBWnKqqATB03)\n",
        "(https://drive.google.com/uc?export=view&id=1q0eWUEj8YWJlYF-lqzD5bBWnKqqATB03)\n",
        "### Plotly outputs for words only\n",
        "![Words](https://drive.google.com/uc?export=view&id=1YnV1lgcsYh4EanO2Oi1wwNHtbob_WZU6)\n",
        "(https://drive.google.com/uc?export=view&id=1YnV1lgcsYh4EanO2Oi1wwNHtbob_WZU6)\n",
        "\n",
        "\n",
        "Upon inspection from plotly, we can observe that most of the technical vocab had a lower sentimentality score, and most of the twitter handles (and almost all twitter handles that had company names), were negative. Considering the context (again) in which these tweets were received, it is not that surprising. \n",
        "\n",
        "As mentioned previous, there were some limitations to the BERT model that was used to create the pipeline. Although a string like (for example) 'This is not amazing!' can be detected well:\n",
        "```\n",
        "sentiment_analysis('This is not amazing!')\n",
        "[{'label': 'NEGATIVE', 'score': 0.9997857213020325}]\n",
        "```\n",
        "A slight variation of the string (eg. 'This is amazing... not!') is not well recognised.\n",
        "```\n",
        "sentiment_analysis('This is amazing... not!')\n",
        "[{'label': 'POSITIVE', 'score': 0.9929170608520508}]\n",
        "```\n",
        "Which is a clear limitation of the model, and should be further investigated (perhaps with some fine-tuning of the model).\n",
        "\n",
        "Whilst other models were considered, it was clear that this version of the BERT model had the best outcomes overall, outdoing other pretrained models that had been fine-tuned for tweets, like `vinai/bertweet_base`. Which was one of the main reasons I had considered using the generalised BERT model. Further, there were the occasional foreign language tweets, but I went with the BERT model again because of the ease of use. There were other models that could use other/multiple languages, but those did not have the speed and accuracy of the BERT model, which was another reason I used this model.\n",
        "\n",
        "The dataset contained some very strange/unusual characters such as 'ï£¿Ã¼Ã²Â°ï£¿Ã¼Ã²Â°'. I did not remove/filter these words/characters out for this dataset specifically, as they were relatively few and far between, and did not appear to have much of an adverse affect on our model predictions.\n",
        "\n",
        "An obvious but crucial point to say is that most of these words (at least for my run) had only had a sample tweet size only slightly greater than 3 occurances. This is obviously not enough to classify the average sentiment of a word (as can be seen in the 'love' example). A larger sample size is crucial to more holistically observe the words of interest in the twitter tech-support space.\n",
        "\n",
        "Again, I would like to thank Spark 64 to for giving me the opportunity to take part in the technical test. I hope that there were not jarring issues with running the Colab Notebook."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FLrvIcdrYvCO"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}